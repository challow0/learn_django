{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'monday', 'to', 'friday', 'most', 'people', 'are', 'busy', 'working', 'or', 'studying', ',', 'but', 'in', 'the', 'evenings', 'and', 'weekends', 'they', 'are', 'free', 'and', '_', 'themselves', '.']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = 'From Monday to Friday most people are busy working or studying, '\\\n",
    "       'but in the evenings and weekends they are free and _ themselves.'\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'monday', 'to', 'friday', 'most', 'people', 'are', 'busy', 'working', 'or', 'studying', ',', 'but', 'in', 'the', 'evenings', 'and', 'weekends', 'they', 'are', 'free', 'and', '[MASK]', 'themselves', '.']\n"
     ]
    }
   ],
   "source": [
    "masked_index = tokenized_text.index('_')\n",
    "\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2293, 2147, 5959, 2377]\n"
     ]
    }
   ],
   "source": [
    "candidates = ['love', 'work', 'enjoy', 'play']\n",
    "\n",
    "candidates_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
    "\n",
    "print(candidates_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2013, 6928, 2000, 5958, 2087, 2111, 2024, 5697, 2551, 2030, 5702, 1010, 2021, 1999, 1996, 16241, 1998, 13499, 2027, 2024, 2489, 1998, 103, 3209, 1012]\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "print(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens_tensor:  tensor([[ 2013,  6928,  2000,  5958,  2087,  2111,  2024,  5697,  2551,  2030,\n",
      "          5702,  1010,  2021,  1999,  1996, 16241,  1998, 13499,  2027,  2024,\n",
      "          2489,  1998,   103,  3209,  1012]])\n",
      "Segments_tensor:  tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [0] * len(tokenized_text)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "print('Tokens_tensor: ', tokens_tensor)\n",
    "\n",
    "print('Segments_tensor: ', segments_tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -7.3524,  -7.3705,  -7.3813,  ...,  -6.7036,  -6.6253,  -4.1512],\n",
      "         [ -8.5638,  -9.0042,  -9.0043,  ...,  -6.2188,  -5.9293,  -5.9213],\n",
      "         [-16.1689, -15.9357, -16.1867,  ..., -12.8809, -13.8796,  -4.9378],\n",
      "         ...,\n",
      "         [ -5.7302,  -6.0601,  -5.5552,  ...,  -5.6121,  -4.4892,  -7.0992],\n",
      "         [ -8.7442,  -8.8843,  -8.7663,  ...,  -8.4347,  -7.4472,  -6.5295],\n",
      "         [-10.8952, -10.9725, -10.8689,  ..., -10.7548, -10.0049,  -7.0908]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "<built-in method size of Tensor object at 0x00000215DA8E3BD0>\n"
     ]
    }
   ],
   "source": [
    "language_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "language_model.eval()\n",
    "\n",
    "predictions = language_model(tokens_tensor, segments_tensors)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "print(predictions.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7453, 3.2638, 6.1241, 2.6489], grad_fn=<IndexBackward>)\n"
     ]
    }
   ],
   "source": [
    "predictions_candidates = predictions[0, masked_index, candidates_ids]\n",
    "\n",
    "print(predictions_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely word is \"enjoy\".\n"
     ]
    }
   ],
   "source": [
    "answer_idx = torch.argmax(predictions_candidates).item()\n",
    "\n",
    "print(f'The most likely word is \"{candidates[answer_idx]}\".')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
